{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Challenge\n",
    "\n",
    "Wine experts can identify wines from specific vineyards through smell and taste, but the factors that give different wines their individual charateristics are actually based on their chemical composition.\n",
    "\n",
    "In this challenge, you must train a classification model to analyze the chemical and visual features of wine samples and classify them based on their cultivar (grape variety).\n",
    "\n",
    "> **Citation**: The data used in this exercise was originally collected by Forina, M. et al.\n",
    ">\n",
    "> PARVUS - An Extendible Package for Data Exploration, Classification and Correlation.\n",
    "Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno,\n",
    "16147 Genoa, Italy.\n",
    ">\n",
    "> It can be downloaded from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository]([http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Run the following cell to load a CSV file of wine data, which consists of 12 numeric features and a classification label with the following classes:\n",
    "\n",
    "- **0** (*variety A*)\n",
    "- **1** (*variety B*)\n",
    "- **2** (*variety C*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Alcohol  Malic_acid   Ash  Alcalinity  Magnesium  Phenols  Flavanoids  \\\n8      14.83        1.64  2.17        14.0         97     2.80        2.98   \n36     13.28        1.64  2.84        15.5        110     2.60        2.68   \n37     13.05        1.65  2.55        18.0         98     2.45        2.43   \n78     12.33        0.99  1.95        14.8        136     1.90        1.85   \n119    12.00        3.43  2.00        19.0         87     2.00        1.64   \n54     13.74        1.67  2.25        16.4        118     2.60        2.90   \n90     12.08        1.83  2.32        18.5         81     1.60        1.50   \n127    11.79        2.13  2.78        28.5         92     2.13        2.24   \n5      14.20        1.76  2.45        15.2        112     3.27        3.39   \n114    12.08        1.39  2.50        22.5         84     2.56        2.29   \n\n     Nonflavanoids  Proanthocyanins  Color_intensity   Hue  \\\n8             0.29             1.98             5.20  1.08   \n36            0.34             1.36             4.60  1.09   \n37            0.29             1.44             4.25  1.12   \n78            0.35             2.76             3.40  1.06   \n119           0.37             1.87             1.28  0.93   \n54            0.21             1.62             5.85  0.92   \n90            0.52             1.64             2.40  1.08   \n127           0.58             1.76             3.00  0.97   \n5             0.34             1.97             6.75  1.05   \n114           0.43             1.04             2.90  0.93   \n\n     OD280_315_of_diluted_wines  Proline  WineVariety  \n8                          2.85     1045            0  \n36                         2.78      880            0  \n37                         2.51     1105            0  \n78                         2.31      750            1  \n119                        3.05      564            1  \n54                         3.20     1060            0  \n90                         2.27      480            1  \n127                        2.44      466            1  \n5                          2.85     1450            0  \n114                        3.19      385            1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alcohol</th>\n      <th>Malic_acid</th>\n      <th>Ash</th>\n      <th>Alcalinity</th>\n      <th>Magnesium</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoids</th>\n      <th>Proanthocyanins</th>\n      <th>Color_intensity</th>\n      <th>Hue</th>\n      <th>OD280_315_of_diluted_wines</th>\n      <th>Proline</th>\n      <th>WineVariety</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>14.83</td>\n      <td>1.64</td>\n      <td>2.17</td>\n      <td>14.0</td>\n      <td>97</td>\n      <td>2.80</td>\n      <td>2.98</td>\n      <td>0.29</td>\n      <td>1.98</td>\n      <td>5.20</td>\n      <td>1.08</td>\n      <td>2.85</td>\n      <td>1045</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>13.28</td>\n      <td>1.64</td>\n      <td>2.84</td>\n      <td>15.5</td>\n      <td>110</td>\n      <td>2.60</td>\n      <td>2.68</td>\n      <td>0.34</td>\n      <td>1.36</td>\n      <td>4.60</td>\n      <td>1.09</td>\n      <td>2.78</td>\n      <td>880</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>13.05</td>\n      <td>1.65</td>\n      <td>2.55</td>\n      <td>18.0</td>\n      <td>98</td>\n      <td>2.45</td>\n      <td>2.43</td>\n      <td>0.29</td>\n      <td>1.44</td>\n      <td>4.25</td>\n      <td>1.12</td>\n      <td>2.51</td>\n      <td>1105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>12.33</td>\n      <td>0.99</td>\n      <td>1.95</td>\n      <td>14.8</td>\n      <td>136</td>\n      <td>1.90</td>\n      <td>1.85</td>\n      <td>0.35</td>\n      <td>2.76</td>\n      <td>3.40</td>\n      <td>1.06</td>\n      <td>2.31</td>\n      <td>750</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>12.00</td>\n      <td>3.43</td>\n      <td>2.00</td>\n      <td>19.0</td>\n      <td>87</td>\n      <td>2.00</td>\n      <td>1.64</td>\n      <td>0.37</td>\n      <td>1.87</td>\n      <td>1.28</td>\n      <td>0.93</td>\n      <td>3.05</td>\n      <td>564</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>13.74</td>\n      <td>1.67</td>\n      <td>2.25</td>\n      <td>16.4</td>\n      <td>118</td>\n      <td>2.60</td>\n      <td>2.90</td>\n      <td>0.21</td>\n      <td>1.62</td>\n      <td>5.85</td>\n      <td>0.92</td>\n      <td>3.20</td>\n      <td>1060</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>12.08</td>\n      <td>1.83</td>\n      <td>2.32</td>\n      <td>18.5</td>\n      <td>81</td>\n      <td>1.60</td>\n      <td>1.50</td>\n      <td>0.52</td>\n      <td>1.64</td>\n      <td>2.40</td>\n      <td>1.08</td>\n      <td>2.27</td>\n      <td>480</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>11.79</td>\n      <td>2.13</td>\n      <td>2.78</td>\n      <td>28.5</td>\n      <td>92</td>\n      <td>2.13</td>\n      <td>2.24</td>\n      <td>0.58</td>\n      <td>1.76</td>\n      <td>3.00</td>\n      <td>0.97</td>\n      <td>2.44</td>\n      <td>466</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.20</td>\n      <td>1.76</td>\n      <td>2.45</td>\n      <td>15.2</td>\n      <td>112</td>\n      <td>3.27</td>\n      <td>3.39</td>\n      <td>0.34</td>\n      <td>1.97</td>\n      <td>6.75</td>\n      <td>1.05</td>\n      <td>2.85</td>\n      <td>1450</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>12.08</td>\n      <td>1.39</td>\n      <td>2.50</td>\n      <td>22.5</td>\n      <td>84</td>\n      <td>2.56</td>\n      <td>2.29</td>\n      <td>0.43</td>\n      <td>1.04</td>\n      <td>2.90</td>\n      <td>0.93</td>\n      <td>3.19</td>\n      <td>385</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the training dataset\n",
    "data = pd.read_csv('data/wine.csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your challenge is to explore the data and train a classification model that achieves an overall *Recall* metric of over 0.95 (95%).\n",
    "\n",
    "> **Note**: There is no single \"correct\" solution. A sample solution is provided in [03 - Wine Classification Solution.ipynb](03%20-%20Wine%20Classification%20Solution.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and evaluate a model\n",
    "\n",
    "Add markdown and code cells as required to to explore the data, train a model, and evaluate the model's predictive performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         0         1         2         3         4         5         6   \\\n0  0.842105  0.191700  0.572193  0.257732  0.619565  0.627586  0.573840   \n1  0.571053  0.205534  0.417112  0.030928  0.326087  0.575862  0.510549   \n2  0.560526  0.320158  0.700535  0.412371  0.336957  0.627586  0.611814   \n3  0.878947  0.239130  0.609626  0.319588  0.467391  0.989655  0.664557   \n4  0.581579  0.365613  0.807487  0.536082  0.521739  0.627586  0.495781   \n\n         7         8         9         10        11        12   13  \n0  0.283019  0.593060  0.372014  0.455285  0.970696  0.561341  0.0  \n1  0.245283  0.274448  0.264505  0.463415  0.780220  0.550642  0.0  \n2  0.320755  0.757098  0.375427  0.447154  0.695971  0.646933  0.0  \n3  0.207547  0.558360  0.556314  0.308943  0.798535  0.857347  0.0  \n4  0.490566  0.444795  0.259386  0.455285  0.608059  0.325963  0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.842105</td>\n      <td>0.191700</td>\n      <td>0.572193</td>\n      <td>0.257732</td>\n      <td>0.619565</td>\n      <td>0.627586</td>\n      <td>0.573840</td>\n      <td>0.283019</td>\n      <td>0.593060</td>\n      <td>0.372014</td>\n      <td>0.455285</td>\n      <td>0.970696</td>\n      <td>0.561341</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.571053</td>\n      <td>0.205534</td>\n      <td>0.417112</td>\n      <td>0.030928</td>\n      <td>0.326087</td>\n      <td>0.575862</td>\n      <td>0.510549</td>\n      <td>0.245283</td>\n      <td>0.274448</td>\n      <td>0.264505</td>\n      <td>0.463415</td>\n      <td>0.780220</td>\n      <td>0.550642</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.560526</td>\n      <td>0.320158</td>\n      <td>0.700535</td>\n      <td>0.412371</td>\n      <td>0.336957</td>\n      <td>0.627586</td>\n      <td>0.611814</td>\n      <td>0.320755</td>\n      <td>0.757098</td>\n      <td>0.375427</td>\n      <td>0.447154</td>\n      <td>0.695971</td>\n      <td>0.646933</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.878947</td>\n      <td>0.239130</td>\n      <td>0.609626</td>\n      <td>0.319588</td>\n      <td>0.467391</td>\n      <td>0.989655</td>\n      <td>0.664557</td>\n      <td>0.207547</td>\n      <td>0.558360</td>\n      <td>0.556314</td>\n      <td>0.308943</td>\n      <td>0.798535</td>\n      <td>0.857347</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.581579</td>\n      <td>0.365613</td>\n      <td>0.807487</td>\n      <td>0.536082</td>\n      <td>0.521739</td>\n      <td>0.627586</td>\n      <td>0.495781</td>\n      <td>0.490566</td>\n      <td>0.444795</td>\n      <td>0.259386</td>\n      <td>0.455285</td>\n      <td>0.608059</td>\n      <td>0.325963</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_numbers = list(range(data.shape[1] - 1))\n",
    "scaler = MinMaxScaler()\n",
    "data = ColumnTransformer(transformers=[('preprocessing', scaler, column_numbers)], remainder=\"passthrough\").fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1].to_numpy(), \n",
    "    data.iloc[:,-1].to_numpy(),\n",
    "    test_size=0.15,\n",
    "    random_state=100\n",
    "    )\n",
    "kfold = KFold(shuffle=True, random_state=100)\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=KFold(n_splits=5, random_state=100, shuffle=True),\n             estimator=RandomForestClassifier(),\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [10, 20, 50, 100],\n                         'n_estimators': [100, 200, 500, 1000]},\n             scoring=<function recall_score at 0x7fabe8e47790>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to evaluate data, and train and evaluate a classification model\n",
    "model = RandomForestClassifier()\n",
    "grid_searchCV = GridSearchCV(model, param_grid=parameters, scoring=recall_score, cv=kfold)\n",
    "grid_searchCV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_searchCV.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 2., 0., 1., 2., 2., 1., 1., 1., 1., 2., 1., 2., 2., 2., 0., 2.,\n       0., 1., 0., 2., 0., 1., 1., 0., 0., 1.])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 2., 0., 1., 2., 2., 1., 1., 1., 1., 2., 1., 2., 2., 2., 0., 2.,\n       0., 1., 0., 2., 0., 1., 1., 0., 0., 1.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         7\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model with new data observation\n",
    "\n",
    "When you're happy with your model's predictive performance, save it and then use it to predict classes for the following two new wine samples:\n",
    "\n",
    "- \\[13.72,1.43,2.5,16.7,108,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285\\]\n",
    "- \\[12.37,0.94,1.36,10.6,88,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code to predict classes for the two new samples\n",
    "unobserved_sample_1 = np.array([13.72,1.43,2.5,16.7,108,3.4,3.67,0.19,2.04,6.8,0.89,2.87,1285]).reshape(1,-1)\n",
    "unobserved_sample_2 = np.array([12.37,0.94,1.36,10.6,88,1.98,0.57,0.28,0.42,1.95,1.05,1.82,520]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(unobserved_sample_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(unobserved_sample_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9eafd9d7e3ef55e88defbeebb178dc58f5692bd504f543a595c474d25c9d4c95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}